/**
 * Helper functions for the custom fetch implementation
 * These functions break down the complex fetch logic into manageable, testable units
 */
import { refreshAccessToken } from "../auth/auth.js";
import { logRequest } from "../logger.js";
import { getCodexInstructions, getModelFamily } from "../prompts/codex.js";
import { transformRequestBody, normalizeModel } from "./request-transformer.js";
import { convertSseToJson, ensureContentType } from "./response-handler.js";
import { PLUGIN_NAME, HTTP_STATUS, OPENAI_HEADERS, OPENAI_HEADER_VALUES, URL_PATHS, ERROR_MESSAGES, LOG_STAGES, } from "../constants.js";
/**
 * Determines if the current auth token needs to be refreshed
 * @param auth - Current authentication state
 * @returns True if token is expired or invalid
 */
export function shouldRefreshToken(auth) {
    return auth.type !== "oauth" || !auth.access || auth.expires < Date.now();
}
/**
 * Refreshes the OAuth token and updates stored credentials
 * @param currentAuth - Current auth state
 * @param client - Opencode client for updating stored credentials
 * @returns Updated auth (throws on failure)
 */
export async function refreshAndUpdateToken(currentAuth, client) {
    const refreshToken = currentAuth.type === "oauth" ? currentAuth.refresh : "";
    const refreshResult = await refreshAccessToken(refreshToken);
    if (refreshResult.type === "failed") {
        throw new Error(ERROR_MESSAGES.TOKEN_REFRESH_FAILED);
    }
    // Update stored credentials
    await client.auth.set({
        path: { id: "openai" },
        body: {
            type: "oauth",
            access: refreshResult.access,
            refresh: refreshResult.refresh,
            expires: refreshResult.expires,
        },
    });
    // Update current auth reference if it's OAuth type
    if (currentAuth.type === "oauth") {
        currentAuth.access = refreshResult.access;
        currentAuth.refresh = refreshResult.refresh;
        currentAuth.expires = refreshResult.expires;
    }
    return currentAuth;
}
/**
 * Extracts URL string from various request input types
 * @param input - Request input (string, URL, or Request object)
 * @returns URL string
 */
export function extractRequestUrl(input) {
    if (typeof input === "string")
        return input;
    if (input instanceof URL)
        return input.toString();
    return input.url;
}
/**
 * Rewrites OpenAI API URLs to Codex backend URLs
 * @param url - Original URL
 * @returns Rewritten URL for Codex backend
 */
export function rewriteUrlForCodex(url) {
    return url.replace(URL_PATHS.RESPONSES, URL_PATHS.CODEX_RESPONSES);
}
/**
 * Transforms request body and logs the transformation
 * Fetches model-specific Codex instructions based on the request model
 *
 * @param init - Request init options
 * @param url - Request URL
 * @param userConfig - User configuration
 * @param codexMode - Enable CODEX_MODE (bridge prompt instead of tool remap)
 * @returns Transformed body and updated init, or undefined if no body
 */
export async function transformRequestForCodex(init, url, userConfig, codexMode = true) {
    if (!init?.body)
        return undefined;
    try {
        const body = JSON.parse(init.body);
        const originalModel = body.model;
        // Normalize model first to determine which instructions to fetch
        // This ensures we get the correct model-specific prompt
        const normalizedModel = normalizeModel(originalModel);
        const modelFamily = getModelFamily(normalizedModel);
        // Log original request
        logRequest(LOG_STAGES.BEFORE_TRANSFORM, {
            url,
            originalModel,
            model: body.model,
            hasTools: !!body.tools,
            hasInput: !!body.input,
            inputLength: body.input?.length,
            codexMode,
            body: body,
        });
        // Fetch model-specific Codex instructions (cached per model family)
        const codexInstructions = await getCodexInstructions(normalizedModel);
        // Transform request body
        const transformedBody = await transformRequestBody(body, codexInstructions, userConfig, codexMode);
        // Log transformed request
        logRequest(LOG_STAGES.AFTER_TRANSFORM, {
            url,
            originalModel,
            normalizedModel: transformedBody.model,
            modelFamily,
            hasTools: !!transformedBody.tools,
            hasInput: !!transformedBody.input,
            inputLength: transformedBody.input?.length,
            reasoning: transformedBody.reasoning,
            textVerbosity: transformedBody.text?.verbosity,
            include: transformedBody.include,
            body: transformedBody,
        });
        return {
            body: transformedBody,
            updatedInit: { ...init, body: JSON.stringify(transformedBody) },
        };
    }
    catch (e) {
        console.error(`[${PLUGIN_NAME}] ${ERROR_MESSAGES.REQUEST_PARSE_ERROR}:`, e);
        return undefined;
    }
}
/**
 * Creates headers for Codex API requests
 * @param init - Request init options
 * @param accountId - ChatGPT account ID
 * @param accessToken - OAuth access token
 * @returns Headers object with all required Codex headers
 */
export function createCodexHeaders(init, accountId, accessToken, opts) {
    const headers = new Headers(init?.headers ?? {});
    headers.delete("x-api-key"); // Remove any existing API key
    headers.set("Authorization", `Bearer ${accessToken}`);
    headers.set(OPENAI_HEADERS.ACCOUNT_ID, accountId);
    headers.set(OPENAI_HEADERS.BETA, OPENAI_HEADER_VALUES.BETA_RESPONSES);
    headers.set(OPENAI_HEADERS.ORIGINATOR, OPENAI_HEADER_VALUES.ORIGINATOR_CODEX);
    const cacheKey = opts?.promptCacheKey;
    if (cacheKey) {
        headers.set(OPENAI_HEADERS.CONVERSATION_ID, cacheKey);
        headers.set(OPENAI_HEADERS.SESSION_ID, cacheKey);
    }
    else {
        headers.delete(OPENAI_HEADERS.CONVERSATION_ID);
        headers.delete(OPENAI_HEADERS.SESSION_ID);
    }
    headers.set("accept", "text/event-stream");
    return headers;
}
/**
 * Handles error responses from the Codex API
 * @param response - Error response from API
 * @returns Original response or mapped retryable response
 */
export async function handleErrorResponse(response) {
    const mapped = await mapUsageLimit404(response);
    const finalResponse = mapped ?? response;
    logRequest(LOG_STAGES.ERROR_RESPONSE, {
        status: finalResponse.status,
        statusText: finalResponse.statusText,
    });
    return finalResponse;
}
/**
 * Handles successful responses from the Codex API
 * Converts SSE to JSON for non-streaming requests (generateText)
 * Passes through SSE for streaming requests (streamText)
 * @param response - Success response from API
 * @param isStreaming - Whether this is a streaming request (stream=true in body)
 * @returns Processed response (SSEâ†’JSON for non-streaming, stream for streaming)
 */
export async function handleSuccessResponse(response, isStreaming) {
    const responseHeaders = ensureContentType(response.headers);
    // For non-streaming requests (generateText), convert SSE to JSON
    if (!isStreaming) {
        return await convertSseToJson(response, responseHeaders);
    }
    // For streaming requests (streamText), return stream as-is
    return new Response(response.body, {
        status: response.status,
        statusText: response.statusText,
        headers: responseHeaders,
    });
}
async function mapUsageLimit404(response) {
    if (response.status !== HTTP_STATUS.NOT_FOUND)
        return null;
    const clone = response.clone();
    let text = "";
    try {
        text = await clone.text();
    }
    catch {
        text = "";
    }
    if (!text)
        return null;
    let code = "";
    try {
        const parsed = JSON.parse(text);
        code = (parsed?.error?.code ?? parsed?.error?.type ?? "").toString();
    }
    catch {
        code = "";
    }
    const haystack = `${code} ${text}`.toLowerCase();
    if (!/usage_limit_reached|usage_not_included|rate_limit_exceeded|usage limit/i.test(haystack)) {
        return null;
    }
    const headers = new Headers(response.headers);
    return new Response(response.body, {
        status: HTTP_STATUS.TOO_MANY_REQUESTS,
        statusText: "Too Many Requests",
        headers,
    });
}
//# sourceMappingURL=fetch-helpers.js.map